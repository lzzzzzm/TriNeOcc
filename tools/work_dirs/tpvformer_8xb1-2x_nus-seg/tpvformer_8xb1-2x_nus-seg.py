_dim_ = 128
_ffn_dim_ = 256
backend_args = None
custom_imports = dict(
    allow_failed_imports=False, imports=[
        'projects.TPVFormer.tpvformer',
    ])
data_prefix = dict(
    CAM_BACK='samples/CAM_BACK',
    CAM_BACK_LEFT='samples/CAM_BACK_LEFT',
    CAM_BACK_RIGHT='samples/CAM_BACK_RIGHT',
    CAM_FRONT='samples/CAM_FRONT',
    CAM_FRONT_LEFT='samples/CAM_FRONT_LEFT',
    CAM_FRONT_RIGHT='samples/CAM_FRONT_RIGHT',
    pts='samples/LIDAR_TOP',
    pts_semantic_mask='lidarseg/v1.0-mini')
data_root = 'data/nuscenes/'
dataset_type = 'NuScenesSegDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='Det3DVisualizationHook'))
default_scope = 'mmdet3d'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
grid_shape = [
    200,
    200,
    16,
]
hybrid_attn_anchors = 16
hybrid_attn_init = 0
hybrid_attn_points = 32
launcher = 'none'
load_from = '../ckpts/tpvformer_8xb1-2x_nus-seg.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
model = dict(
    backbone=dict(
        dcn=dict(deform_groups=1, fallback_on_stride=False, type='DCNv2'),
        depth=101,
        frozen_stages=1,
        init_cfg=dict(
            checkpoint='checkpoints/tpvformer_pretrained_fcos3d_r101_dcn.pth',
            prefix='backbone.',
            type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='BN2d'),
        norm_eval=True,
        num_stages=4,
        out_indices=(
            1,
            2,
            3,
        ),
        stage_with_dcn=(
            False,
            False,
            True,
            True,
        ),
        style='caffe',
        type='mmdet.ResNet'),
    data_preprocessor=dict(
        batch_augments=[
            dict(
                mode=1,
                offset=False,
                prob=0.7,
                ratio=0.5,
                rotate=1,
                type='GridMask',
                use_h=True,
                use_w=True),
        ],
        mean=[
            103.53,
            116.28,
            123.675,
        ],
        pad_size_divisor=32,
        std=[
            1.0,
            1.0,
            1.0,
        ],
        type='TPVFormerDataPreprocessor',
        voxel=True,
        voxel_layer=dict(
            grid_shape=[
                200,
                200,
                16,
            ],
            max_num_points=-1,
            max_voxels=-1,
            point_cloud_range=[
                -51.2,
                -51.2,
                -5.0,
                51.2,
                51.2,
                3.0,
            ]),
        voxel_type='cylindrical'),
    decode_head=dict(
        ce_input='voxel',
        hidden_dims=256,
        ignore_index=0,
        in_dims=128,
        loss_ce=dict(
            avg_non_ignore=True,
            class_weight=None,
            loss_weight=1.0,
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_lovasz=dict(loss_weight=1.0, reduction='none', type='LovaszLoss'),
        lovasz_input='points',
        num_classes=17,
        out_dims=128,
        scale_h=1,
        scale_w=1,
        scale_z=1,
        tpv_h=200,
        tpv_w=200,
        tpv_z=16,
        type='TPVFormerDecoder'),
    encoder=dict(
        embed_dims=128,
        num_layers=5,
        num_points_in_pillar=[
            4,
            32,
            32,
        ],
        num_points_in_pillar_cross_view=[
            16,
            16,
            16,
        ],
        pc_range=[
            -51.2,
            -51.2,
            -5.0,
            51.2,
            51.2,
            3.0,
        ],
        positional_encoding=dict(
            h=200,
            num_feats=[
                48,
                48,
                32,
            ],
            type='TPVFormerPositionalEncoding',
            w=200,
            z=16),
        return_intermediate=False,
        tpv_h=200,
        tpv_w=200,
        tpv_z=16,
        transformerlayers=[
            dict(
                attn_cfgs=[
                    dict(
                        dropout=0.1,
                        embed_dims=128,
                        init_mode=0,
                        num_anchors=16,
                        num_heads=8,
                        num_points=32,
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVCrossViewHybridAttention'),
                    dict(
                        deformable_attention=dict(
                            embed_dims=128,
                            floor_sampling_offset=False,
                            num_heads=8,
                            num_levels=4,
                            num_points=[
                                8,
                                64,
                                64,
                            ],
                            num_z_anchors=[
                                4,
                                32,
                                32,
                            ],
                            tpv_h=200,
                            tpv_w=200,
                            tpv_z=16,
                            type='TPVMSDeformableAttention3D'),
                        dropout=0.1,
                        embed_dims=128,
                        num_cams=6,
                        pc_range=[
                            -51.2,
                            -51.2,
                            -5.0,
                            51.2,
                            51.2,
                            3.0,
                        ],
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVImageCrossAttention'),
                ],
                feedforward_channels=256,
                ffn_dropout=0.1,
                operation_order=(
                    'self_attn',
                    'norm',
                    'cross_attn',
                    'norm',
                    'ffn',
                    'norm',
                ),
                type='TPVFormerLayer'),
            dict(
                attn_cfgs=[
                    dict(
                        dropout=0.1,
                        embed_dims=128,
                        init_mode=0,
                        num_anchors=16,
                        num_heads=8,
                        num_points=32,
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVCrossViewHybridAttention'),
                    dict(
                        deformable_attention=dict(
                            embed_dims=128,
                            floor_sampling_offset=False,
                            num_heads=8,
                            num_levels=4,
                            num_points=[
                                8,
                                64,
                                64,
                            ],
                            num_z_anchors=[
                                4,
                                32,
                                32,
                            ],
                            tpv_h=200,
                            tpv_w=200,
                            tpv_z=16,
                            type='TPVMSDeformableAttention3D'),
                        dropout=0.1,
                        embed_dims=128,
                        num_cams=6,
                        pc_range=[
                            -51.2,
                            -51.2,
                            -5.0,
                            51.2,
                            51.2,
                            3.0,
                        ],
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVImageCrossAttention'),
                ],
                feedforward_channels=256,
                ffn_dropout=0.1,
                operation_order=(
                    'self_attn',
                    'norm',
                    'cross_attn',
                    'norm',
                    'ffn',
                    'norm',
                ),
                type='TPVFormerLayer'),
            dict(
                attn_cfgs=[
                    dict(
                        dropout=0.1,
                        embed_dims=128,
                        init_mode=0,
                        num_anchors=16,
                        num_heads=8,
                        num_points=32,
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVCrossViewHybridAttention'),
                    dict(
                        deformable_attention=dict(
                            embed_dims=128,
                            floor_sampling_offset=False,
                            num_heads=8,
                            num_levels=4,
                            num_points=[
                                8,
                                64,
                                64,
                            ],
                            num_z_anchors=[
                                4,
                                32,
                                32,
                            ],
                            tpv_h=200,
                            tpv_w=200,
                            tpv_z=16,
                            type='TPVMSDeformableAttention3D'),
                        dropout=0.1,
                        embed_dims=128,
                        num_cams=6,
                        pc_range=[
                            -51.2,
                            -51.2,
                            -5.0,
                            51.2,
                            51.2,
                            3.0,
                        ],
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVImageCrossAttention'),
                ],
                feedforward_channels=256,
                ffn_dropout=0.1,
                operation_order=(
                    'self_attn',
                    'norm',
                    'cross_attn',
                    'norm',
                    'ffn',
                    'norm',
                ),
                type='TPVFormerLayer'),
            dict(
                attn_cfgs=[
                    dict(
                        dropout=0.1,
                        embed_dims=128,
                        init_mode=0,
                        num_anchors=16,
                        num_heads=8,
                        num_points=32,
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVCrossViewHybridAttention'),
                ],
                feedforward_channels=256,
                ffn_dropout=0.1,
                operation_order=(
                    'self_attn',
                    'norm',
                    'ffn',
                    'norm',
                ),
                type='TPVFormerLayer'),
            dict(
                attn_cfgs=[
                    dict(
                        dropout=0.1,
                        embed_dims=128,
                        init_mode=0,
                        num_anchors=16,
                        num_heads=8,
                        num_points=32,
                        tpv_h=200,
                        tpv_w=200,
                        tpv_z=16,
                        type='TPVCrossViewHybridAttention'),
                ],
                feedforward_channels=256,
                ffn_dropout=0.1,
                operation_order=(
                    'self_attn',
                    'norm',
                    'ffn',
                    'norm',
                ),
                type='TPVFormerLayer'),
        ],
        type='TPVFormerEncoder'),
    neck=dict(
        add_extra_convs='on_output',
        in_channels=[
            512,
            1024,
            2048,
        ],
        init_cfg=dict(
            checkpoint='checkpoints/tpvformer_pretrained_fcos3d_r101_dcn.pth',
            prefix='neck.',
            type='Pretrained'),
        num_outs=4,
        out_channels=128,
        relu_before_extra_convs=True,
        start_level=0,
        type='mmdet.FPN'),
    type='TPVFormer')
num_heads = 8
num_points = [
    8,
    64,
    64,
]
num_points_in_pillar = [
    4,
    32,
    32,
]
optim_wrapper = dict(
    clip_grad=dict(max_norm=35, norm_type=2),
    optimizer=dict(lr=0.0002, type='AdamW', weight_decay=0.01),
    paramwise_cfg=dict(custom_keys=dict(backbone=dict(lr_mult=0.1))),
    type='OptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=500, start_factor=1e-05, type='LinearLR'),
    dict(
        T_max=24,
        begin=0,
        by_epoch=True,
        convert_to_iter_based=True,
        eta_min=1e-06,
        type='CosineAnnealingLR'),
]
point_cloud_range = [
    -51.2,
    -51.2,
    -5.0,
    51.2,
    51.2,
    3.0,
]
resume = False
scale_h = 1
scale_w = 1
scale_z = 1
self_cross_layer = dict(
    attn_cfgs=[
        dict(
            dropout=0.1,
            embed_dims=128,
            init_mode=0,
            num_anchors=16,
            num_heads=8,
            num_points=32,
            tpv_h=200,
            tpv_w=200,
            tpv_z=16,
            type='TPVCrossViewHybridAttention'),
        dict(
            deformable_attention=dict(
                embed_dims=128,
                floor_sampling_offset=False,
                num_heads=8,
                num_levels=4,
                num_points=[
                    8,
                    64,
                    64,
                ],
                num_z_anchors=[
                    4,
                    32,
                    32,
                ],
                tpv_h=200,
                tpv_w=200,
                tpv_z=16,
                type='TPVMSDeformableAttention3D'),
            dropout=0.1,
            embed_dims=128,
            num_cams=6,
            pc_range=[
                -51.2,
                -51.2,
                -5.0,
                51.2,
                51.2,
                3.0,
            ],
            tpv_h=200,
            tpv_w=200,
            tpv_z=16,
            type='TPVImageCrossAttention'),
    ],
    feedforward_channels=256,
    ffn_dropout=0.1,
    operation_order=(
        'self_attn',
        'norm',
        'cross_attn',
        'norm',
        'ffn',
        'norm',
    ),
    type='TPVFormerLayer')
self_layer = dict(
    attn_cfgs=[
        dict(
            dropout=0.1,
            embed_dims=128,
            init_mode=0,
            num_anchors=16,
            num_heads=8,
            num_points=32,
            tpv_h=200,
            tpv_w=200,
            tpv_z=16,
            type='TPVCrossViewHybridAttention'),
    ],
    feedforward_channels=256,
    ffn_dropout=0.1,
    operation_order=(
        'self_attn',
        'norm',
        'ffn',
        'norm',
    ),
    type='TPVFormerLayer')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='nuscenes_infos_val.pkl',
        data_prefix=dict(
            CAM_BACK='samples/CAM_BACK',
            CAM_BACK_LEFT='samples/CAM_BACK_LEFT',
            CAM_BACK_RIGHT='samples/CAM_BACK_RIGHT',
            CAM_FRONT='samples/CAM_FRONT',
            CAM_FRONT_LEFT='samples/CAM_FRONT_LEFT',
            CAM_FRONT_RIGHT='samples/CAM_FRONT_RIGHT',
            pts='samples/LIDAR_TOP',
            pts_semantic_mask='lidarseg/v1.0-mini'),
        data_root='data/nuscenes/',
        pipeline=[
            dict(
                backend_args=None,
                color_type='unchanged',
                num_views=6,
                to_float32=False,
                type='BEVLoadMultiViewImageFromFiles'),
            dict(
                backend_args=None,
                coord_type='LIDAR',
                load_dim=5,
                type='LoadPointsFromFile',
                use_dim=3),
            dict(
                seg_3d_dtype='np.uint8',
                type='LoadAnnotations3D',
                with_attr_label=False,
                with_bbox_3d=False,
                with_label_3d=False,
                with_seg_3d=True),
            dict(type='SegLabelMapping'),
            dict(
                keys=[
                    'img',
                    'points',
                    'pts_semantic_mask',
                ],
                meta_keys=[
                    'lidar2img',
                ],
                type='Pack3DDetInputs'),
        ],
        test_mode=True,
        type='NuScenesSegDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(type='SegMetric')
test_pipeline = [
    dict(
        backend_args=None,
        color_type='unchanged',
        num_views=6,
        to_float32=False,
        type='BEVLoadMultiViewImageFromFiles'),
    dict(
        backend_args=None,
        coord_type='LIDAR',
        load_dim=5,
        type='LoadPointsFromFile',
        use_dim=3),
    dict(
        seg_3d_dtype='np.uint8',
        type='LoadAnnotations3D',
        with_attr_label=False,
        with_bbox_3d=False,
        with_label_3d=False,
        with_seg_3d=True),
    dict(type='SegLabelMapping'),
    dict(
        keys=[
            'img',
            'points',
            'pts_semantic_mask',
        ],
        meta_keys=[
            'lidar2img',
        ],
        type='Pack3DDetInputs'),
]
tpv_h_ = 200
tpv_w_ = 200
tpv_z_ = 16
train_cfg = dict(max_epochs=24, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='nuscenes_infos_train.pkl',
        data_prefix=dict(
            CAM_BACK='samples/CAM_BACK',
            CAM_BACK_LEFT='samples/CAM_BACK_LEFT',
            CAM_BACK_RIGHT='samples/CAM_BACK_RIGHT',
            CAM_FRONT='samples/CAM_FRONT',
            CAM_FRONT_LEFT='samples/CAM_FRONT_LEFT',
            CAM_FRONT_RIGHT='samples/CAM_FRONT_RIGHT',
            pts='samples/LIDAR_TOP',
            pts_semantic_mask='lidarseg/v1.0-mini'),
        data_root='data/nuscenes/',
        pipeline=[
            dict(
                backend_args=None,
                color_type='unchanged',
                num_views=6,
                to_float32=False,
                type='BEVLoadMultiViewImageFromFiles'),
            dict(
                backend_args=None,
                coord_type='LIDAR',
                load_dim=5,
                type='LoadPointsFromFile',
                use_dim=3),
            dict(
                seg_3d_dtype='np.uint8',
                type='LoadAnnotations3D',
                with_attr_label=False,
                with_bbox_3d=False,
                with_label_3d=False,
                with_seg_3d=True),
            dict(
                transforms=dict(type='PhotoMetricDistortion3D'),
                type='MultiViewWrapper'),
            dict(type='SegLabelMapping'),
            dict(
                keys=[
                    'img',
                    'points',
                    'pts_semantic_mask',
                ],
                meta_keys=[
                    'lidar2img',
                ],
                type='Pack3DDetInputs'),
        ],
        test_mode=False,
        type='NuScenesSegDataset'),
    drop_last=True,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(
        backend_args=None,
        color_type='unchanged',
        num_views=6,
        to_float32=False,
        type='BEVLoadMultiViewImageFromFiles'),
    dict(
        backend_args=None,
        coord_type='LIDAR',
        load_dim=5,
        type='LoadPointsFromFile',
        use_dim=3),
    dict(
        seg_3d_dtype='np.uint8',
        type='LoadAnnotations3D',
        with_attr_label=False,
        with_bbox_3d=False,
        with_label_3d=False,
        with_seg_3d=True),
    dict(
        transforms=dict(type='PhotoMetricDistortion3D'),
        type='MultiViewWrapper'),
    dict(type='SegLabelMapping'),
    dict(
        keys=[
            'img',
            'points',
            'pts_semantic_mask',
        ],
        meta_keys=[
            'lidar2img',
        ],
        type='Pack3DDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='nuscenes_infos_val.pkl',
        data_prefix=dict(
            CAM_BACK='samples/CAM_BACK',
            CAM_BACK_LEFT='samples/CAM_BACK_LEFT',
            CAM_BACK_RIGHT='samples/CAM_BACK_RIGHT',
            CAM_FRONT='samples/CAM_FRONT',
            CAM_FRONT_LEFT='samples/CAM_FRONT_LEFT',
            CAM_FRONT_RIGHT='samples/CAM_FRONT_RIGHT',
            pts='samples/LIDAR_TOP',
            pts_semantic_mask='lidarseg/v1.0-mini'),
        data_root='data/nuscenes/',
        pipeline=[
            dict(
                backend_args=None,
                color_type='unchanged',
                num_views=6,
                to_float32=False,
                type='BEVLoadMultiViewImageFromFiles'),
            dict(
                backend_args=None,
                coord_type='LIDAR',
                load_dim=5,
                type='LoadPointsFromFile',
                use_dim=3),
            dict(
                seg_3d_dtype='np.uint8',
                type='LoadAnnotations3D',
                with_attr_label=False,
                with_bbox_3d=False,
                with_label_3d=False,
                with_seg_3d=True),
            dict(type='SegLabelMapping'),
            dict(
                keys=[
                    'img',
                    'points',
                    'pts_semantic_mask',
                ],
                meta_keys=[
                    'lidar2img',
                ],
                type='Pack3DDetInputs'),
        ],
        test_mode=True,
        type='NuScenesSegDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(type='SegMetric')
val_pipeline = [
    dict(
        backend_args=None,
        color_type='unchanged',
        num_views=6,
        to_float32=False,
        type='BEVLoadMultiViewImageFromFiles'),
    dict(
        backend_args=None,
        coord_type='LIDAR',
        load_dim=5,
        type='LoadPointsFromFile',
        use_dim=3),
    dict(
        seg_3d_dtype='np.uint8',
        type='LoadAnnotations3D',
        with_attr_label=False,
        with_bbox_3d=False,
        with_label_3d=False,
        with_seg_3d=True),
    dict(type='SegLabelMapping'),
    dict(
        keys=[
            'img',
            'points',
            'pts_semantic_mask',
        ],
        meta_keys=[
            'lidar2img',
        ],
        type='Pack3DDetInputs'),
]
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='Det3DLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs\\tpvformer_8xb1-2x_nus-seg'
